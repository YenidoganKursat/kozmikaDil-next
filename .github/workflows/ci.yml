name: CI

on:
  push:
    branches: [ "master", "main", "codex/**" ]
  pull_request:
    branches: [ "master", "main" ]
  workflow_dispatch:
    inputs:
      gpu_backend:
        description: "GPU backend suite to validate"
        required: false
        default: "all"
        type: choice
        options:
          - all
          - cuda
          - rocm_hip
          - oneapi_sycl
          - opencl
          - vulkan_compute
          - metal

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install toolchain
        run: |
          sudo apt-get -o Acquire::Retries=3 update
          sudo apt-get -o Acquire::Retries=3 install -y cmake ninja-build clang g++ make python3 python3-pip libmpfr-dev libgmp-dev default-jdk

      - name: Architecture and coverage guard
        run: python3 ./.github/scripts/architecture_guard.py --max-lines 5000

      - name: Precision policy guard
        run: python3 ./.github/scripts/precision_policy_guard.py

      - name: Platform readiness guard
        run: python3 ./.github/scripts/platform_readiness_gate.py

      - name: Configure
        run: cmake -S . -B build -G Ninja -DCMAKE_BUILD_TYPE=Release -DSPARK_BUILD_TESTS=ON

      - name: Build
        run: cmake --build build -j 4

      - name: Discover CTest entries
        run: ctest --test-dir build -N

      - name: Run CTest suite (core)
        run: |
          ctest --test-dir build \
            --parallel 4 \
            --output-on-failure \
            --timeout 1800 \
            -E "sparkc_phase5_crosslang_primitives|sparkc_phase9_tests" \
            --output-junit ./build/ctest_core.junit.xml \
            --output-log ./build/ctest_core.log

      - name: Cross-language primitive correctness (CI profile)
        run: |
          python3 ./tests/phase5/primitives/crosslang_native_primitives_tests.py \
            --int-loops 25000 \
            --int-extreme-random 64 \
            --float-loops 500 \
            --float-python-loops 500 \
            --float-extreme-random 32 \
            --single-op-loops 120000 \
            --single-op-runs 2

      - name: Stability replay (critical phases)
        run: |
          ctest --test-dir build \
            --output-on-failure \
            --timeout 1800 \
            --repeat until-fail:3 \
            -R "sparkc_typecheck_tests|sparkc_codegen_tests|sparkc_phase(5|6|7|8|10)_tests" \
            --output-junit ./build/ctest_replay.junit.xml \
            --output-log ./build/ctest_replay.log

      - name: Upload CTest logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-ctest-logs
          path: |
            build/ctest_core.log
            build/ctest_replay.log
            build/ctest_core.junit.xml
            build/ctest_replay.junit.xml
            build/Testing/Temporary/LastTest.log
            bench/results/ci_platform_matrix.json
          if-no-files-found: warn

  portability-host-matrix:
    name: Portability Host Matrix (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    defaults:
      run:
        shell: bash
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install build deps for Linux probe
        if: runner.os == 'Linux'
        run: |
          sudo apt-get -o Acquire::Retries=3 update
          sudo apt-get -o Acquire::Retries=3 install -y cmake ninja-build clang g++ make python3 python3-pip

      - name: Build sparkc for runtime + GPU probes
        run: |
          if [ "$RUNNER_OS" = "Linux" ]; then
            cmake -S . -B build -G Ninja -DCMAKE_BUILD_TYPE=Release -DSPARK_BUILD_TESTS=OFF
          else
            cmake -S . -B build -DCMAKE_BUILD_TYPE=Release -DSPARK_BUILD_TESTS=OFF
          fi
          cmake --build build --parallel 4 --target sparkc --config Release

      - name: Python compile checks (phase10 scripts)
        run: |
          python -m py_compile scripts/phase10/advanced_capability_smoke.py
          python -m py_compile scripts/phase10/platform_performance_smoke.py
          python -m py_compile scripts/phase10/target_catalog.py
          python -m py_compile .github/scripts/platform_support_gate.py
          python -m py_compile scripts/phase10/gpu_backend_catalog.py
          python -m py_compile scripts/phase10/gpu_backend_perf.py
          python -m py_compile scripts/phase10/gpu_backend_runtime_perf.py
          python -m py_compile scripts/phase10/platform_matrix.py
          python -m py_compile scripts/phase10/gpu_smoke_matrix.py
          python -m py_compile .github/scripts/microcontroller_readiness_gate.py

      - name: Run advanced capability smoke across all CPU/embedded targets
        run: |
          python scripts/phase10/advanced_capability_smoke.py \
            --all-targets \
            --json-out bench/results/phase10_advanced_capability_${{ runner.os }}.json

      - name: Run cross-platform performance smoke across all CPU/embedded targets
        run: |
          python scripts/phase10/platform_performance_smoke.py \
            --all-targets \
            --runs 1 \
            --warmup 0 \
            --timeout 30 \
            --json-out bench/results/phase10_cross_platform_perf_${{ runner.os }}.json

      - name: Generate platform matrix report
        run: |
          python scripts/phase10/platform_matrix.py \
            --preset market \
            --include-experimental \
            --include-embedded \
            --include-gpu-experimental \
            --include-gpu-planning \
            --run-multiarch-probe \
            --multiarch-lto thin \
            --json-out bench/results/phase10_platform_matrix_${{ runner.os }}.json

      - name: Generate GPU smoke matrix (report-only)
        run: |
          python scripts/phase10/gpu_smoke_matrix.py \
            --backends all \
            --include-planning \
            --json-out bench/results/phase10_gpu_smoke_${{ runner.os }}.json

      - name: Resolve required GPU backends from policy
        id: gpu_required_backends
        run: |
          required_backends="$(python3 - <<'PY'
          import json
          import os

          with open("docs/platform_support_policy.json", "r", encoding="utf-8") as fp:
              policy = json.load(fp)

          host = os.environ.get("RUNNER_OS", "")
          cfg = policy.get("gpu", {}).get("required_available_targets", {})
          required = set()

          def normalize(values):
              if values is None:
                  return []
              if isinstance(values, str):
                  values = values.strip()
                  return [values] if values else []
              if isinstance(values, list):
                  return [str(v).strip() for v in values if str(v).strip()]
              return []

          if isinstance(cfg, dict) and isinstance(cfg.get("required"), dict):
              required.update(normalize(cfg["required"].get("all")))
              required.update(normalize(cfg["required"].get(host)))
          else:
              required.update(normalize(cfg.get("all")))
              required.update(normalize(cfg.get(host)))

          print(','.join(sorted(required)))
          PY
          )"
          echo "backends=$required_backends" >> "$GITHUB_OUTPUT"
        shell: bash

      - name: Prepare GPU infra for required backends (best-effort)
        continue-on-error: true
        run: |
          python3 scripts/phase10/gpu_backend_infra.py \
            --backends "${{ steps.gpu_required_backends.outputs.backends }}" \
            --provision \
            --json-out bench/results/phase10_gpu_infra_${{ runner.os }}.json

      - name: Enforce strict GPU availability (best-effort)
        if: runner.os == 'Linux'
        continue-on-error: true
        run: |
          python scripts/phase10/gpu_smoke_matrix.py \
            --backends all \
            --include-planning \
            --fail-on-unavailable "${{ steps.gpu_required_backends.outputs.backends }}" \
            --json-out bench/results/phase10_gpu_smoke_${{ runner.os }}_strict.json

      - name: Generate GPU backend perf matrix (report-only)
        run: |
          python scripts/phase10/gpu_backend_perf.py \
            --backends all \
            --include-planning \
            --runs 7 \
            --warmup 2 \
            --json-out bench/results/phase10_gpu_perf_${{ runner.os }}.json

      - name: Generate GPU runtime perf matrix (best-effort)
        run: |
          runtime_perf_args="--require-portable-routing --require-gpu-coverage"
          python scripts/phase10/gpu_backend_runtime_perf.py \
            --program bench/programs/phase8/matmul_core_f64.k \
            --runs 3 \
            --warmup 1 \
            --max-perf \
            --allow-missing-runtime \
            $runtime_perf_args \
            --json-out bench/results/phase10_gpu_runtime_perf_${{ runner.os }}.json \
            --csv-out bench/results/phase10_gpu_runtime_perf_${{ runner.os }}.csv

      - name: Generate GPU runtime perf matrix (1000x workload)
        run: |
          python scripts/phase10/gpu_backend_runtime_perf.py \
            --program bench/programs/phase8/matmul_core_f64.k \
            --workload-scale 1000 \
            --runs 1 \
            --warmup 0 \
            --max-perf \
            --allow-missing-runtime \
            --program-diff-tolerance 0.001 \
            --json-out bench/results/phase10_gpu_runtime_perf_${{ runner.os }}_x1000.json \
            --csv-out bench/results/phase10_gpu_runtime_perf_${{ runner.os }}_x1000.csv

      - name: Validate microcontroller/mcu readiness
        run: |
          python .github/scripts/microcontroller_readiness_gate.py \
            --require-interpret-smoke \
            --json-out bench/results/phase10_microcontroller_gate_${{ runner.os }}.json

      - name: Run unified portability support gate
        continue-on-error: true
        run: |
          python .github/scripts/platform_support_gate.py \
            --platform-matrix bench/results/phase10_platform_matrix_${{ runner.os }}.json \
            --advanced-capability bench/results/phase10_advanced_capability_${{ runner.os }}.json \
            --cross-perf bench/results/phase10_cross_platform_perf_${{ runner.os }}.json \
            --microcontroller bench/results/phase10_microcontroller_gate_${{ runner.os }}.json \
            --gpu-smoke bench/results/phase10_gpu_smoke_${{ runner.os }}.json \
            --report-out bench/results/phase10_platform_support_gate_${{ runner.os }}.json

      - name: Upload platform matrix report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-platform-matrix-${{ runner.os }}
          path: |
            bench/results/phase10_advanced_capability_${{ runner.os }}.json
            bench/results/phase10_cross_platform_perf_${{ runner.os }}.json
            bench/results/phase10_platform_matrix_${{ runner.os }}.json
            bench/results/phase10_gpu_smoke_${{ runner.os }}.json
            bench/results/phase10_gpu_perf_${{ runner.os }}.json
            bench/results/phase10_gpu_runtime_perf_${{ runner.os }}.json
            bench/results/phase10_gpu_runtime_perf_${{ runner.os }}.csv
            bench/results/phase10_gpu_runtime_perf_${{ runner.os }}_x1000.json
            bench/results/phase10_gpu_runtime_perf_${{ runner.os }}_x1000.csv
            bench/results/phase10_platform_support_gate_${{ runner.os }}.json
            bench/results/phase10_microcontroller_gate_${{ runner.os }}.json
            bench/results/phase10_gpu_smoke_${{ runner.os }}_strict.json
            bench/results/phase10_gpu_infra_${{ runner.os }}.json
          if-no-files-found: warn

  gpu-backend-cicd:
    if: github.event_name == 'workflow_dispatch'
    name: GPU Backend CD (${{ inputs.gpu_backend }})
    uses: ./.github/workflows/gpu-backend-cicd.yml
    with:
      backend: ${{ github.event.inputs.gpu_backend || 'all' }}

  compiler-matrix-build:
    name: Compiler Matrix Build (${{ matrix.name }})
    runs-on: ubuntu-latest
    timeout-minutes: 35
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: gcc
            cc: gcc
            cxx: g++
          - name: clang
            cc: clang
            cxx: clang++
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install toolchain
        run: |
          sudo apt-get -o Acquire::Retries=3 update
          sudo apt-get -o Acquire::Retries=3 install -y cmake ninja-build clang g++ make python3 libmpfr-dev libgmp-dev

      - name: Configure
        env:
          CC: ${{ matrix.cc }}
          CXX: ${{ matrix.cxx }}
        run: cmake -S . -B build_${{ matrix.name }} -G Ninja -DCMAKE_BUILD_TYPE=Release -DSPARK_BUILD_TESTS=ON

      - name: Build
        run: cmake --build build_${{ matrix.name }} -j 4

      - name: CTest smoke set
        run: |
          ctest --test-dir build_${{ matrix.name }} \
            --output-on-failure \
            --timeout 1200 \
            --output-junit ./build_${{ matrix.name }}/ctest_smoke.junit.xml \
            -R "sparkc_smoke_test|sparkc_parser_tests|sparkc_eval_tests|sparkc_typecheck_tests|sparkc_codegen_tests"

  sanitizer:
    name: Sanitizer (ASan + UBSan)
    runs-on: ubuntu-latest
    timeout-minutes: 40
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install toolchain
        run: |
          sudo apt-get -o Acquire::Retries=3 update
          sudo apt-get -o Acquire::Retries=3 install -y cmake ninja-build clang g++ make python3 libmpfr-dev libgmp-dev

      - name: Configure (sanitizers)
        run: |
          cmake -S . -B build_san -G Ninja \
            -DCMAKE_BUILD_TYPE=RelWithDebInfo \
            -DSPARK_BUILD_TESTS=ON \
            -DCMAKE_C_COMPILER=clang \
            -DCMAKE_CXX_COMPILER=clang++ \
            -DCMAKE_C_FLAGS="-fsanitize=address,undefined -fno-omit-frame-pointer" \
            -DCMAKE_CXX_FLAGS="-fsanitize=address,undefined -fno-omit-frame-pointer" \
            -DCMAKE_EXE_LINKER_FLAGS="-fsanitize=address,undefined" \
            -DCMAKE_SHARED_LINKER_FLAGS="-fsanitize=address,undefined"

      - name: Build
        run: cmake --build build_san -j 4

      - name: Run sanitizer smoke tests
        env:
          ASAN_OPTIONS: "detect_leaks=0:halt_on_error=1:strict_string_checks=1"
          UBSAN_OPTIONS: "halt_on_error=1:print_stacktrace=1"
        run: |
          ctest --test-dir build_san \
            --output-on-failure \
            --timeout 1800 \
            --output-junit ./build_san/ctest_san.junit.xml \
            -R "sparkc_smoke_test|sparkc_parser_tests|sparkc_eval_tests|sparkc_typecheck_tests|sparkc_codegen_tests|sparkc_phase5_tests"

  thread-sanitizer:
    name: Thread Sanitizer (TSan)
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install toolchain
        run: |
          sudo apt-get -o Acquire::Retries=3 update
          sudo apt-get -o Acquire::Retries=3 install -y cmake ninja-build clang g++ make python3 libmpfr-dev libgmp-dev

      - name: Configure (TSan)
        run: |
          cmake -S . -B build_tsan -G Ninja \
            -DCMAKE_BUILD_TYPE=RelWithDebInfo \
            -DSPARK_BUILD_TESTS=ON \
            -DCMAKE_C_COMPILER=clang \
            -DCMAKE_CXX_COMPILER=clang++ \
            -DCMAKE_C_FLAGS="-fsanitize=thread -fno-omit-frame-pointer -O1" \
            -DCMAKE_CXX_FLAGS="-fsanitize=thread -fno-omit-frame-pointer -O1" \
            -DCMAKE_EXE_LINKER_FLAGS="-fsanitize=thread" \
            -DCMAKE_SHARED_LINKER_FLAGS="-fsanitize=thread"

      - name: Build
        run: cmake --build build_tsan -j 4

      - name: Run concurrency sanitizer tests
        env:
          TSAN_OPTIONS: "halt_on_error=1 history_size=7 second_deadlock_stack=1"
        run: |
          ctest --test-dir build_tsan \
            --output-on-failure \
            --timeout 1800 \
            --parallel 1 \
            --output-junit ./build_tsan/ctest_tsan.junit.xml \
            -R "sparkc_smoke_test"

  perf-regression:
    name: Performance Regression Gate
    runs-on: ubuntu-latest
    timeout-minutes: 25
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install toolchain
        run: |
          sudo apt-get -o Acquire::Retries=3 update
          sudo apt-get -o Acquire::Retries=3 install -y cmake ninja-build clang g++ make python3 python3-pip libmpfr-dev libgmp-dev

      - name: Configure
        run: cmake -S . -B build -G Ninja -DCMAKE_BUILD_TYPE=Release -DSPARK_BUILD_TESTS=OFF

      - name: Build sparkc
        run: cmake --build build -j 4 --target sparkc

      - name: Run perf regression gate
        run: |
          python3 ./.github/scripts/perf_regression_gate.py \
            --baseline ./.github/perf/perf_baseline.json \
            --output ./bench/results/ci_perf_regression.json

      - name: Upload perf gate report
        uses: actions/upload-artifact@v4
        with:
          name: ci-perf-regression
          path: bench/results/ci_perf_regression.json
